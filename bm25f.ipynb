{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jKs7xC6lIvYL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pymorphy2-dicts in c:\\users\\acer\\anaconda3\\lib\\site-packages (2.4.393442.3710985)\n",
      "Requirement already up-to-date: DAWG-Python in c:\\users\\acer\\anaconda3\\lib\\site-packages (0.7.2)\n",
      "Requirement already up-to-date: pymorphy2[fast] in c:\\users\\acer\\anaconda3\\lib\\site-packages (0.8)\n",
      "Requirement already satisfied, skipping upgrade: pymorphy2-dicts<3.0,>=2.4 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pymorphy2[fast]) (2.4.393442.3710985)\n",
      "Requirement already satisfied, skipping upgrade: docopt>=0.6 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pymorphy2[fast]) (0.6.2)\n",
      "Requirement already satisfied, skipping upgrade: dawg-python>=0.7 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pymorphy2[fast]) (0.7.2)\n",
      "Requirement already satisfied, skipping upgrade: DAWG>=0.7.3; extra == \"fast\" in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pymorphy2[fast]) (0.8.0)\n",
      "Requirement already up-to-date: nltk in c:\\users\\acer\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied, skipping upgrade: regex in c:\\users\\acer\\anaconda3\\lib\\site-packages (from nltk) (2020.5.14)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in c:\\users\\acer\\anaconda3\\lib\\site-packages (from nltk) (4.46.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib in c:\\users\\acer\\anaconda3\\lib\\site-packages (from nltk) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: click in c:\\users\\acer\\anaconda3\\lib\\site-packages (from nltk) (7.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "великий\n"
     ]
    }
   ],
   "source": [
    "%run prepare_some_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Document = namedtuple('Document',['description','author','keywords',\n",
    "                                  'title','body_a','body_h1',\n",
    "                                  'body_h3','body_strong',\n",
    "                                  'body_rest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nwgiPweulW0b"
   },
   "outputs": [],
   "source": [
    "def create_dict(words):\n",
    "    counter=defaultdict(int)\n",
    "    for word in words:\n",
    "        counter[word]+=1\n",
    "    return (dict(counter),len(words))\n",
    "    \n",
    "\n",
    "def create_docs():\n",
    "    IDF_lem=defaultdict(int)\n",
    "    docs=[None]*(len(get_id)+1)\n",
    "    docs[0]=(dict(),Document(*[0]*9))\n",
    "\n",
    "    i=0\n",
    "\n",
    "    with open('bm_docs.txt','r', encoding = 'utf-8', errors = 'ignore') as f:\n",
    "        for line in f:\n",
    "            words=line.rstrip('\\n').split('\\t')\n",
    "            doc_id=int(words[0])\n",
    "\n",
    "            words=[words[0],*map(lambda string:' '.join(map(add_cash,\n",
    "                                                            string.split())),\n",
    "                                 words[1:])]\n",
    "\n",
    "            words_description=words[1].split()\n",
    "\n",
    "            words_author=words[2].split()\n",
    "\n",
    "            words_keywords=words[3].split()\n",
    "\n",
    "            words_title=words[4].split()\n",
    "\n",
    "            words_a=words[5].split()\n",
    "            words_h1=words[6].split()\n",
    "            words_h3=words[7].split()\n",
    "            words_strong=words[8].split()\n",
    "            words_rest=words[9].split()\n",
    "\n",
    "\n",
    "            all_words=set()\n",
    "            feature=defaultdict(lambda:[0]*9)\n",
    "            lens=[0]*9\n",
    "\n",
    "            for ind,words in enumerate(\n",
    "                [words_description,\n",
    "                words_author,\n",
    "                words_keywords,\n",
    "                words_title,\n",
    "                words_a,\n",
    "                words_h1,\n",
    "                words_h3,\n",
    "                words_strong,\n",
    "                words_rest\n",
    "                 ]):\n",
    "                for word in words:\n",
    "                    feature[word][ind]+=1\n",
    "                    all_words.add(word)\n",
    "                lens[ind]+=len(words)\n",
    "\n",
    "\n",
    "            for word in all_words:\n",
    "                IDF_lem[word]+=1\n",
    "\n",
    "            opt_feature=dict()\n",
    "            for key in feature:\n",
    "                opt_feature[key]=Document(*feature[key])\n",
    "\n",
    "            docs[doc_id]=(opt_feature,Document(*lens))\n",
    "\n",
    "            i+=1\n",
    "            if i%500==0:\n",
    "                print(i)\n",
    "                \n",
    "    return (docs,IDF_lem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YIjv7D8yoJZI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "docs,IDF_lem=create_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_len=np.zeros((len(docs)-1,9))\n",
    "for i,doc in enumerate(docs[1:]):\n",
    "    D_len[i]=np.array([*doc[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.000e+00 0.000e+00 2.100e+01 9.000e+00 2.030e+02 9.400e+01 2.210e+02\n",
      " 1.460e+02 3.399e+04]\n"
     ]
    }
   ],
   "source": [
    "print(D_len[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6HTX4QmZu-ej"
   },
   "outputs": [],
   "source": [
    "def IDF(word,N,l):\n",
    "    n=IDF_lem[word]\n",
    "    return log(l+(N-n)/n)\n",
    "\n",
    "def calculate_mean_length(docvec):\n",
    "    mean_length=(D_len*np.array([docvec])).sum()\n",
    "    return mean_length/len(get_id)\n",
    "\n",
    "def BM25F(query,doc_id,docvec,mean_length,k1,b,l):\n",
    "    score=0\n",
    "    doc=docs[doc_id]\n",
    "    dl=sum(map(lambda x,y:x*y,doc[1],docvec))\n",
    "    for word in query:\n",
    "        if word in doc[0]:\n",
    "            f=sum(map(lambda x,y:x*y,doc[0][word],docvec))\n",
    "            score+=(IDF(word,len(get_id),l)*\n",
    "                    (k1+1)*f/(k1*(1-b+b*dl/mean_length)+f))\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dLZRw6uq8Rz2"
   },
   "outputs": [],
   "source": [
    "candidates,_=generate_candidates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "KEIEGEPuNU2b",
    "outputId": "71598641-a9f6-43ec-8cc8-edb14c66f2e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(description=5, author=11, keywords=3, title=7, body_a=1, body_h1=1, body_h3=1, body_strong=1, body_rest=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docvec=Document(description=10, author=25, \n",
    "                keywords=1, title=200, \n",
    "                body_a=1, body_h1=20, \n",
    "                body_h3=1, body_strong=1, \n",
    "                body_rest=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "ud3eB59kEiHs",
    "outputId": "cd54bea2-a626-4ccb-c94a-cb3a739681ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "k1=500\n",
    "b=0.75\n",
    "\n",
    "l=2\n",
    "\n",
    "\n",
    "mean_length=calculate_mean_length(docvec)\n",
    "best_n=10\n",
    "\n",
    "query_ext=dict()\n",
    "with open('queries.fixed.txt',encoding='utf-8-sig') as f:\n",
    "    with open('bm25res.txt','w') as out:         \n",
    "        for i,line in enumerate(f):\n",
    "            query_id,raw_query=line.split('\\t')\n",
    "            query=string_lem(raw_query.strip()).split()\n",
    "        \n",
    "            out.write(query_id+'\\t')\n",
    "            for cand in candidates[int(query_id)]:\n",
    "                score,doc_id=(BM25F(query,cand,docvec,mean_length,k1,b,l),cand)\n",
    "                out.write(str(score)+','+str(doc_id))\n",
    "                out.write(' ')\n",
    "            out.write('\\n')\n",
    "\n",
    "            if i%100==0:\n",
    "                print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Text relevance BM25F.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
