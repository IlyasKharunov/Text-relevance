{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "if1-FK9vIPHi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pymorphy2-dicts in c:\\users\\acer\\anaconda3\\lib\\site-packages (2.4.393442.3710985)\n",
      "Requirement already up-to-date: DAWG-Python in c:\\users\\acer\\anaconda3\\lib\\site-packages (0.7.2)\n",
      "Requirement already up-to-date: pymorphy2[fast] in c:\\users\\acer\\anaconda3\\lib\\site-packages (0.8)\n",
      "Requirement already satisfied, skipping upgrade: pymorphy2-dicts<3.0,>=2.4 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pymorphy2[fast]) (2.4.393442.3710985)\n",
      "Requirement already satisfied, skipping upgrade: docopt>=0.6 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pymorphy2[fast]) (0.6.2)\n",
      "Requirement already satisfied, skipping upgrade: dawg-python>=0.7 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pymorphy2[fast]) (0.7.2)\n",
      "Requirement already satisfied, skipping upgrade: DAWG>=0.7.3; extra == \"fast\" in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pymorphy2[fast]) (0.8.0)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.5.zip (1.4 MB)\n",
      "Requirement already satisfied, skipping upgrade: click in c:\\users\\acer\\anaconda3\\lib\\site-packages (from nltk) (7.1.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib in c:\\users\\acer\\anaconda3\\lib\\site-packages (from nltk) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: regex in c:\\users\\acer\\anaconda3\\lib\\site-packages (from nltk) (2020.5.14)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in c:\\users\\acer\\anaconda3\\lib\\site-packages (from nltk) (4.46.0)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py): started\n",
      "  Building wheel for nltk (setup.py): finished with status 'done'\n",
      "  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434680 sha256=3d4e7aa45cc5e6e32f241941e0e4e9bb1bc9de193f8e3ac8ebd1ffa274ec1c91\n",
      "  Stored in directory: c:\\users\\acer\\appdata\\local\\pip\\cache\\wheels\\45\\6c\\46\\a1865e7ba706b3817f5d1b2ff7ce8996aabdd0d03d47ba0266\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.4.4\n",
      "    Uninstalling nltk-3.4.4:\n",
      "      Successfully uninstalled nltk-3.4.4\n",
      "Successfully installed nltk-3.5\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pymorphy2-dicts\n",
    "!pip install --upgrade DAWG-Python\n",
    "!pip install --upgrade pymorphy2[fast]\n",
    "!pip install --upgrade nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VGlWt-VmIclY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "великий\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict,namedtuple\n",
    "from functools import reduce\n",
    "from zipfile import ZipFile\n",
    "from math import log\n",
    "import heapq\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "from time import time\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "from nltk.corpus import stopwords as stpw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "великий\n"
     ]
    }
   ],
   "source": [
    "print(morph.parse('величайший')[0].normal_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cash=dict()\n",
    "stopwords=set(stpw.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wxnaNKhwaLSH"
   },
   "outputs": [],
   "source": [
    "mysyn = {'сущ' : 'существительное', 'прил' : 'прилагательное', \n",
    "         'майнкрафт' : 'minecraft', 'теле2' : 'tele2', \n",
    "         'кунг' : 'kung', 'фу' : 'fu', \n",
    "         'панда' : 'panda', 'sberbank' : 'сбербанк', \n",
    "         'г' : 'год', 'гта' : 'gta', \n",
    "         'майн' : 'minecraft', 'сан' : 'san', \n",
    "         'андреас' : 'andreas', 'megafon' : 'мегафон', \n",
    "         'андроид' : 'android', 'гиг' : 'gb', \n",
    "         'виндовс' : 'windows', 'винд' : 'windows', \n",
    "         'скайп' : 'skype', 'stalker' : 'сталкер', \n",
    "         'ммр' : 'mmr', 'поу' : 'pou', \n",
    "         'тандер' : 'thunder', 'вар' : 'war', \n",
    "         'бмп' : 'bmp', 'вконтакте' : 'вк', \n",
    "         'vk' : 'вк', 'инстаграм' : 'instagram', \n",
    "         'пдф' : 'pdf', 'ютуба' : 'youtube', \n",
    "         'биос' : 'bios', 'ps' : 'photoshop', \n",
    "         'юсб' : 'usb', 'самсунг' : 'samsung', \n",
    "         'тег' : 'tag', 'скайрим' : 'skyrim', \n",
    "         'дть' : 'demo', 'дискорд' : 'discord', \n",
    "         'киви' : 'kiwi', 'симс' : 'sims', \n",
    "         'айфон' : 'iphone', 'майкрософт' : 'microsoft', \n",
    "         'эксель' : 'excel'}\n",
    "\n",
    "cash.update(mysyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O6zFiIrdvEtY"
   },
   "outputs": [],
   "source": [
    "get_id=dict()\n",
    "get_url=dict()\n",
    "with open('urls.numerate.txt') as f:\n",
    "    for line in f:\n",
    "        ind,url=line.split('\\t')\n",
    "        url=url.strip()\n",
    "        \n",
    "        ind=int(ind)\n",
    "        get_id[url]=ind\n",
    "        get_url[ind]=url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMGq8AgIIefT"
   },
   "outputs": [],
   "source": [
    "def process_string(s):\n",
    "    return ''.join(map(lambda x:x.lower() if x.isalpha() or x.isdigit()\n",
    "                                else ' ' if x not in set(['.','!','?','\\n'])\n",
    "                                else '.',s)) \n",
    "\n",
    "def add_cash(word):\n",
    "    if word not in cash:\n",
    "        cash[word]=morph.parse(word)[0].normal_form\n",
    "    if cash[word] in cash:\n",
    "        return cash[cash[word]]\n",
    "    return cash[word]\n",
    "        \n",
    "def process_string_lem(s):\n",
    "    return ' '.join(map(add_cash,s.split()))\n",
    "      \n",
    "def string_lem(s):\n",
    "    return process_string_lem(process_string(s)) \n",
    "\n",
    "def generate_candidates():\n",
    "    with open('sample.technosphere.ir1.textrelevance.submission.txt','r') as f:\n",
    "        f.readline()\n",
    "        candidates=defaultdict(list)\n",
    "        reverse_candidates=defaultdict(list)\n",
    "        for line in f:\n",
    "            query_id,doc_id=list(map(int,line.strip().split(',')))\n",
    "            candidates[query_id].append(doc_id)\n",
    "            reverse_candidates[doc_id].append(query_id)\n",
    "        return candidates,reverse_candidates\n",
    "\n",
    "candidates,reverse_candidates=generate_candidates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 922,
     "status": "error",
     "timestamp": 1590270635249,
     "user": {
      "displayName": "Олег Вербин",
      "photoUrl": "",
      "userId": "04805874271739164744"
     },
     "user_tz": -180
    },
    "id": "OeAiczdIIji1",
    "outputId": "1673c2c9-16ae-47cf-dec4-909d8d36b306"
   },
   "outputs": [],
   "source": [
    "get_query=dict()\n",
    "get_query_id=dict()\n",
    "with open('queries.fixed.txt','r',encoding='utf-8-sig') as f:\n",
    "    for line in f:\n",
    "        query_id,words=line.split('\\t')\n",
    "        get_query[int(query_id)]=process_string(words).strip('\\n').replace('.',' ')\n",
    "        get_query_id[get_query[int(query_id)]]=int(query_id)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOqL0dyEeWOBFGoHFT2tuhX",
   "collapsed_sections": [],
   "name": "Pre_ini.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
